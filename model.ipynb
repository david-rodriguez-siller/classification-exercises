{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f0bc4c",
   "metadata": {},
   "source": [
    "### Decision Tree Model Exercises\n",
    "\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7f18054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import acquire\n",
    "import prepare\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19b379c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3254f",
   "metadata": {},
   "source": [
    "What is your baseline prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ba4c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline prediction is that passangers did not survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c2b48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare titanic\n",
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['deck', 'embarked', 'class']\n",
    "titanic = titanic.drop(columns=cols_to_drop)\n",
    "titanic['embark_town'] = titanic.embark_town.fillna(value='Southampton')\n",
    "dummy_titanic = pd.get_dummies(titanic[['sex', 'embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "titanic = titanic.drop(columns = ['sex', 'embark_town'])\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ed80208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3  22.0      1      0   7.2500      0   \n",
       "1             1         1       1  38.0      1      0  71.2833      0   \n",
       "2             2         1       3  26.0      0      0   7.9250      1   \n",
       "\n",
       "   sex_male  embark_town_Queenstown  embark_town_Southampton  \n",
       "0         1                       0                        1  \n",
       "1         0                       0                        0  \n",
       "2         0                       0                        1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39bbd835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id                 0\n",
       "survived                     0\n",
       "pclass                       0\n",
       "age                        177\n",
       "sibsp                        0\n",
       "parch                        0\n",
       "fare                         0\n",
       "alone                        0\n",
       "sex_male                     0\n",
       "embark_town_Queenstown       0\n",
       "embark_town_Southampton      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are some nulls in the age column\n",
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "420bd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf0323a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8b93c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "52756d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             498 non-null    int64  \n",
      " 1   survived                 498 non-null    int64  \n",
      " 2   pclass                   498 non-null    int64  \n",
      " 3   age                      498 non-null    float64\n",
      " 4   sibsp                    498 non-null    int64  \n",
      " 5   parch                    498 non-null    int64  \n",
      " 6   fare                     498 non-null    float64\n",
      " 7   alone                    498 non-null    int64  \n",
      " 8   sex_male                 498 non-null    uint8  \n",
      " 9   embark_town_Queenstown   498 non-null    uint8  \n",
      " 10  embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(3)\n",
      "memory usage: 36.5 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b40ede03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd1006",
   "metadata": {},
   "source": [
    "What is your baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ffa2d41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = (0 == train.survived).mean()\n",
    "\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3aead",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc0d6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e398cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with a max_depth value of 5\n",
    "titanic_clf = DecisionTreeClassifier(max_depth = 5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a92d0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_clf = titanic_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "192ecf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = titanic_clf.predict(X_train)\n",
    "#y_pred  ==> array output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94480071",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6ac93480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(titanic_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de9134fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[296,  11],\n",
       "       [ 58, 133]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_m = confusion_matrix(y_train, y_pred)\n",
    "c_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9efc1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did not survive</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Did not survive</th>\n",
       "      <td>296</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Did not survive  Survived\n",
       "Did not survive              296        11\n",
       "Survived                      58       133"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Did not survive', 'Survived']\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(c_m, index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6fa0bd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b09de8",
   "metadata": {},
   "source": [
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "38c376e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'.format(titanic_clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7bf24df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       132\n",
      "           1       0.74      0.62      0.68        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.76      0.74      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = titanic_clf.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734e60d",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2bbadcff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth value: 5\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       132\n",
      "           1       0.74      0.62      0.68        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.76      0.74      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 6\n",
      "Accuracy of Decision Tree classifier on training set: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       307\n",
      "           1       0.89      0.77      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.88      0.86      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       132\n",
      "           1       0.73      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 7\n",
      "Accuracy of Decision Tree classifier on training set: 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       307\n",
      "           1       0.88      0.84      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.89      0.89      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       132\n",
      "           1       0.71      0.67      0.69        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.76      0.75      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 8\n",
      "Accuracy of Decision Tree classifier on training set: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       307\n",
      "           1       0.94      0.86      0.90       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       132\n",
      "           1       0.73      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 9\n",
      "Accuracy of Decision Tree classifier on training set: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       307\n",
      "           1       0.96      0.91      0.94       191\n",
      "\n",
      "    accuracy                           0.95       498\n",
      "   macro avg       0.95      0.94      0.95       498\n",
      "weighted avg       0.95      0.95      0.95       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       132\n",
      "           1       0.70      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 10\n",
      "Accuracy of Decision Tree classifier on training set: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       307\n",
      "           1       0.98      0.92      0.95       191\n",
      "\n",
      "    accuracy                           0.96       498\n",
      "   macro avg       0.97      0.96      0.96       498\n",
      "weighted avg       0.96      0.96      0.96       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       132\n",
      "           1       0.70      0.70      0.70        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 11\n",
      "Accuracy of Decision Tree classifier on training set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       307\n",
      "           1       1.00      0.94      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       132\n",
      "           1       0.70      0.70      0.70        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 12\n",
      "Accuracy of Decision Tree classifier on training set: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       307\n",
      "           1       0.99      0.97      0.98       191\n",
      "\n",
      "    accuracy                           0.99       498\n",
      "   macro avg       0.99      0.99      0.99       498\n",
      "weighted avg       0.99      0.99      0.99       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78       132\n",
      "           1       0.65      0.68      0.67        82\n",
      "\n",
      "    accuracy                           0.74       214\n",
      "   macro avg       0.72      0.73      0.73       214\n",
      "weighted avg       0.74      0.74      0.74       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 13\n",
      "Accuracy of Decision Tree classifier on training set: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       307\n",
      "           1       1.00      0.98      0.99       191\n",
      "\n",
      "    accuracy                           0.99       498\n",
      "   macro avg       0.99      0.99      0.99       498\n",
      "weighted avg       0.99      0.99      0.99       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       132\n",
      "           1       0.66      0.70      0.68        82\n",
      "\n",
      "    accuracy                           0.75       214\n",
      "   macro avg       0.73      0.74      0.74       214\n",
      "weighted avg       0.75      0.75      0.75       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 14\n",
      "Accuracy of Decision Tree classifier on training set: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.98      0.99       191\n",
      "\n",
      "    accuracy                           0.99       498\n",
      "   macro avg       1.00      0.99      0.99       498\n",
      "weighted avg       0.99      0.99      0.99       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       132\n",
      "           1       0.68      0.70      0.69        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.74      0.75      0.74       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 15\n",
      "Accuracy of Decision Tree classifier on training set: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.98      0.99       191\n",
      "\n",
      "    accuracy                           0.99       498\n",
      "   macro avg       1.00      0.99      0.99       498\n",
      "weighted avg       0.99      0.99      0.99       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       132\n",
      "           1       0.67      0.71      0.69        82\n",
      "\n",
      "    accuracy                           0.75       214\n",
      "   macro avg       0.74      0.74      0.74       214\n",
      "weighted avg       0.76      0.75      0.75       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 16\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       132\n",
      "           1       0.65      0.71      0.68        82\n",
      "\n",
      "    accuracy                           0.74       214\n",
      "   macro avg       0.73      0.74      0.73       214\n",
      "weighted avg       0.75      0.74      0.74       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 17\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       307\n",
      "           1       1.00      0.99      1.00       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      1.00      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78       132\n",
      "           1       0.64      0.71      0.67        82\n",
      "\n",
      "    accuracy                           0.73       214\n",
      "   macro avg       0.72      0.73      0.72       214\n",
      "weighted avg       0.74      0.73      0.74       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 18\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       307\n",
      "           1       1.00      1.00      1.00       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      1.00      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78       132\n",
      "           1       0.65      0.72      0.68        82\n",
      "\n",
      "    accuracy                           0.74       214\n",
      "   macro avg       0.73      0.74      0.73       214\n",
      "weighted avg       0.75      0.74      0.75       214\n",
      "\n",
      "---------------------------------------\n",
      "max_depth value: 19\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       307\n",
      "           1       1.00      1.00      1.00       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      1.00      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "Accuracy of Decision Tree classifier on validate set: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78       132\n",
      "           1       0.65      0.72      0.68        82\n",
      "\n",
      "    accuracy                           0.74       214\n",
      "   macro avg       0.73      0.74      0.73       214\n",
      "weighted avg       0.75      0.74      0.75       214\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 20):\n",
    "    print('max_depth value: {}'.format(i))\n",
    "    titanic_clf = DecisionTreeClassifier(max_depth = i, random_state = 123)\n",
    "    titanic_clf = titanic_clf.fit(X_train, y_train)\n",
    "    y_pred = titanic_clf.predict(X_train)\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(titanic_clf.score(X_train, y_train)))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('Accuracy of Decision Tree classifier on validate set: {:.2f}'.format(titanic_clf.score(X_validate, y_validate)))\n",
    "    y_pred = titanic_clf.predict(X_validate)\n",
    "    print(classification_report(y_validate, y_pred))\n",
    "    print('-------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c700d",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've observed that the higher the depth the better the performance on the in-sample\n",
    "# data but thay may be to overfitting too (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144fa65",
   "metadata": {},
   "source": [
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth values 6 and 8 perform the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aefbea",
   "metadata": {},
   "source": [
    "### Random Forest Model Exercises\n",
    "\n",
    "Continue working in your `model` file with titanic data to do the following: \n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4afa14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "465d3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 10,\n",
    "                           random_state = 123, \n",
    "                           min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "731678cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "da27e9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16359522 0.08740554 0.15093152 0.04708349 0.02672832 0.18238905\n",
      " 0.01822827 0.28960813 0.01169783 0.02233262]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5e5b2537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
       "       'sex_male', 'embark_town_Queenstown', 'embark_town_Southampton'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "94406251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0585af57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "069c1470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       307\n",
      "           1       1.00      0.94      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 = did not survive, 1 = survived\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dce5b9",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9324029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'.format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6112ab45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[307,   0],\n",
       "       [ 11, 180]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_m = confusion_matrix(y_train, y_pred)\n",
    "c_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a13d80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did not survive</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Did not survive</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Did not survive  Survived\n",
       "Did not survive              307         0\n",
       "Survived                      11       180"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Did not survive', 'Survived']\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(c_m, index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6fdf0dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       307\n",
      "           1       1.00      0.94      0.97       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.98      0.97      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b8729",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0d9f8adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'.format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4703d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116  16]\n",
      " [ 26  56]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_validate)\n",
    "print(confusion_matrix(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "788f65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did not survive</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Did not survive</th>\n",
       "      <td>116</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Did not survive  Survived\n",
       "Did not survive              116        16\n",
       "Survived                      26        56"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Did not survive', 'Survived']\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_validate, y_pred), index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1793a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       132\n",
      "           1       0.78      0.68      0.73        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346f239",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "32b44043",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth value: 19\n",
      "min_samples_leaf value: 2\n",
      "Accuracy of Random Forest model on training set: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       307\n",
      "           1       0.97      0.87      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.95      0.93      0.93       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       132\n",
      "           1       0.81      0.71      0.75        82\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.82      0.80      0.81       214\n",
      "weighted avg       0.82      0.82      0.82       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 3\n",
      "Accuracy of Random Forest model on training set: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       307\n",
      "           1       0.95      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       132\n",
      "           1       0.81      0.67      0.73        82\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 4\n",
      "Accuracy of Random Forest model on training set: 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       307\n",
      "           1       0.93      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       132\n",
      "           1       0.79      0.66      0.72        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.78       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 5\n",
      "Accuracy of Random Forest model on training set: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       132\n",
      "           1       0.79      0.66      0.72        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.78       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 6\n",
      "Accuracy of Random Forest model on training set: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       132\n",
      "           1       0.78      0.61      0.68        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.75      0.76       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 7\n",
      "Accuracy of Random Forest model on training set: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       307\n",
      "           1       0.90      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.87      0.87      0.87       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       132\n",
      "           1       0.76      0.62      0.68        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.78      0.75      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 8\n",
      "Accuracy of Random Forest model on training set: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90       307\n",
      "           1       0.91      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       132\n",
      "           1       0.77      0.62      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.75      0.76       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 9\n",
      "Accuracy of Random Forest model on training set: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.91      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       132\n",
      "           1       0.81      0.61      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.80      0.76      0.77       214\n",
      "weighted avg       0.80      0.79      0.79       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 10\n",
      "Accuracy of Random Forest model on training set: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       307\n",
      "           1       0.88      0.71      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.84       498\n",
      "weighted avg       0.85      0.85      0.85       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       132\n",
      "           1       0.77      0.62      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.75      0.76       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 11\n",
      "Accuracy of Random Forest model on training set: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       132\n",
      "           1       0.77      0.59      0.67        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.78      0.74      0.75       214\n",
      "weighted avg       0.78      0.78      0.77       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest model on training set: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       132\n",
      "           1       0.80      0.60      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.75      0.76       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 13\n",
      "Accuracy of Random Forest model on training set: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.89      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       132\n",
      "           1       0.78      0.60      0.68        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.78      0.75      0.75       214\n",
      "weighted avg       0.78      0.78      0.77       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 14\n",
      "Accuracy of Random Forest model on training set: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.67      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       132\n",
      "           1       0.80      0.60      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.75      0.76       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 15\n",
      "Accuracy of Random Forest model on training set: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       132\n",
      "           1       0.79      0.60      0.68        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.75      0.76       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 16\n",
      "Accuracy of Random Forest model on training set: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       307\n",
      "           1       0.91      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.86       132\n",
      "           1       0.86      0.59      0.70        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.82      0.76      0.78       214\n",
      "weighted avg       0.81      0.80      0.79       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 17\n",
      "Accuracy of Random Forest model on training set: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85       132\n",
      "           1       0.84      0.59      0.69        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.81      0.76      0.77       214\n",
      "weighted avg       0.81      0.80      0.79       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 18\n",
      "Accuracy of Random Forest model on training set: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       132\n",
      "           1       0.83      0.61      0.70        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.81      0.77      0.78       214\n",
      "weighted avg       0.81      0.80      0.80       214\n",
      "\n",
      "-----------------------------------------------------\n",
      "max_depth value: 19\n",
      "min_samples_leaf value: 19\n",
      "Accuracy of Random Forest model on training set: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "Accuracy of Random Forest model on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       132\n",
      "           1       0.79      0.61      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.76      0.77       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_depth = 20\n",
    "for i in range(2, max_depth):\n",
    "    depth = max_depth - 1\n",
    "    print('max_depth value: {}'.format(depth))\n",
    "    print('min_samples_leaf value: {}'.format(i))\n",
    "    rf = RandomForestClassifier(max_depth = depth,\n",
    "                           random_state = 123, \n",
    "                           min_samples_leaf = i)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_train)\n",
    "    print('Accuracy of Random Forest model on training set: {:.2f}'.format(rf.score(X_train, y_train)))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('Accuracy of Random Forest model on validate set: {:.2f}'.format(rf.score(X_validate, y_validate)))\n",
    "    y_pred = rf.predict(X_validate)\n",
    "    print(classification_report(y_validate, y_pred))\n",
    "    print('-----------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fca928",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01d671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa7bac3",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d939f",
   "metadata": {},
   "source": [
    "### KNN Model Exercises\n",
    "\n",
    "Continue working in your model file with the titanic dataset. \n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)​."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3434b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5692e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876f7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aceab9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbbc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb2bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58004e40",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc78b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35aa46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  41]\n",
      " [ 87 104]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a461ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       307\n",
      "           1       0.72      0.54      0.62       191\n",
      "\n",
      "    accuracy                           0.74       498\n",
      "   macro avg       0.74      0.71      0.71       498\n",
      "weighted avg       0.74      0.74      0.73       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f398e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 266, 41, 87)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839180a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7429718875502008\n",
      "True Positive Rate: 0.5445026178010471\n",
      "False Positive Rate: 0.13355048859934854\n",
      "True Negative Rate: 0.8664495114006515\n",
      "False Negative Rate: 0.45549738219895286\n",
      "Precision: 0.7172413793103448\n",
      "Recall: 0.5445026178010471\n",
      "F1 Score: 0.6190476190476191\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24d23b",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89579ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.61\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69d6daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dffeab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99 33]\n",
      " [50 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da9c7be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70       132\n",
      "           1       0.49      0.39      0.44        82\n",
      "\n",
      "    accuracy                           0.61       214\n",
      "   macro avg       0.58      0.57      0.57       214\n",
      "weighted avg       0.60      0.61      0.60       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c56ae1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 99, 33, 50)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_validate,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95ca2c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6121495327102804\n",
      "True Positive Rate: 0.3902439024390244\n",
      "False Positive Rate: 0.25\n",
      "True Negative Rate: 0.75\n",
      "False Negative Rate: 0.6097560975609756\n",
      "Precision: 0.49230769230769234\n",
      "Recall: 0.3902439024390244\n",
      "F1 Score: 0.435374149659864\n",
      "Support (0): 82\n",
      "Support (1): 132\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5cf0f",
   "metadata": {},
   "source": [
    "4. Run through steps 2-3 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6978c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edc16021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f59f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c95b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbc16d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "270bf629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[284  23]\n",
      " [128  63]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed9f6099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79       307\n",
      "           1       0.73      0.33      0.45       191\n",
      "\n",
      "    accuracy                           0.70       498\n",
      "   macro avg       0.71      0.63      0.62       498\n",
      "weighted avg       0.71      0.70      0.66       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8136d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.62\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "629c00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae5f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115  17]\n",
      " [ 65  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d94c282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74       132\n",
      "           1       0.50      0.21      0.29        82\n",
      "\n",
      "    accuracy                           0.62       214\n",
      "   macro avg       0.57      0.54      0.52       214\n",
      "weighted avg       0.59      0.62      0.57       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196152d3",
   "metadata": {},
   "source": [
    "5. Run through setps 2-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a387a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 20, weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8feadf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a56ae6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4642e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b856094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.67\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9487dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[288  19]\n",
      " [147  44]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a363d7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.78       307\n",
      "           1       0.70      0.23      0.35       191\n",
      "\n",
      "    accuracy                           0.67       498\n",
      "   macro avg       0.68      0.58      0.56       498\n",
      "weighted avg       0.68      0.67      0.61       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e8bc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a83230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "916938db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122  10]\n",
      " [ 65  17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0b51b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       132\n",
      "           1       0.63      0.21      0.31        82\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.64      0.57      0.54       214\n",
      "weighted avg       0.64      0.65      0.59       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd30a0a",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8ddd095",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of KNN: 1\n",
      "Accuracy of KNN classifier on training set: 1.00\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 2\n",
      "Accuracy of KNN classifier on training set: 0.78\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 3\n",
      "Accuracy of KNN classifier on training set: 0.80\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 4\n",
      "Accuracy of KNN classifier on training set: 0.76\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 5\n",
      "Accuracy of KNN classifier on training set: 0.74\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 6\n",
      "Accuracy of KNN classifier on training set: 0.72\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 7\n",
      "Accuracy of KNN classifier on training set: 0.72\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 8\n",
      "Accuracy of KNN classifier on training set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 9\n",
      "Accuracy of KNN classifier on training set: 0.71\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 10\n",
      "Accuracy of KNN classifier on training set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 11\n",
      "Accuracy of KNN classifier on training set: 0.71\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 12\n",
      "Accuracy of KNN classifier on training set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 13\n",
      "Accuracy of KNN classifier on training set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 14\n",
      "Accuracy of KNN classifier on training set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 15\n",
      "Accuracy of KNN classifier on training set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 16\n",
      "Accuracy of KNN classifier on training set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 17\n",
      "Accuracy of KNN classifier on training set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 18\n",
      "Accuracy of KNN classifier on training set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 19\n",
      "Accuracy of KNN classifier on training set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 20\n",
      "Accuracy of KNN classifier on training set: 0.67\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "knn_no = range(1, 21)\n",
    "for i in knn_no:\n",
    "    print('Number of KNN: {}'.format(i))\n",
    "    knn = KNeighborsClassifier(n_neighbors = i, weights = 'uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_train)\n",
    "    #print(classification_report(y_train, y_pred))\n",
    "    print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827feb1",
   "metadata": {},
   "source": [
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1df37108",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of KNN: 1\n",
      "Accuracy of KNN classifier on validate set: 1.00\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 2\n",
      "Accuracy of KNN classifier on validate set: 0.79\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 3\n",
      "Accuracy of KNN classifier on validate set: 0.79\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 4\n",
      "Accuracy of KNN classifier on validate set: 0.71\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 5\n",
      "Accuracy of KNN classifier on validate set: 0.74\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 6\n",
      "Accuracy of KNN classifier on validate set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 7\n",
      "Accuracy of KNN classifier on validate set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 8\n",
      "Accuracy of KNN classifier on validate set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 9\n",
      "Accuracy of KNN classifier on validate set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 10\n",
      "Accuracy of KNN classifier on validate set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 11\n",
      "Accuracy of KNN classifier on validate set: 0.70\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 12\n",
      "Accuracy of KNN classifier on validate set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 13\n",
      "Accuracy of KNN classifier on validate set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 14\n",
      "Accuracy of KNN classifier on validate set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 15\n",
      "Accuracy of KNN classifier on validate set: 0.69\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 16\n",
      "Accuracy of KNN classifier on validate set: 0.67\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 17\n",
      "Accuracy of KNN classifier on validate set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 18\n",
      "Accuracy of KNN classifier on validate set: 0.67\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 19\n",
      "Accuracy of KNN classifier on validate set: 0.68\n",
      "-----------------------------------------------------\n",
      "Number of KNN: 20\n",
      "Accuracy of KNN classifier on validate set: 0.67\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "knn_no = range(1, 21)\n",
    "for i in knn_no:\n",
    "    print('Number of KNN: {}'.format(i))\n",
    "    knn = KNeighborsClassifier(n_neighbors = i, weights = 'uniform')\n",
    "    knn.fit(X_validate, y_validate)\n",
    "    y_pred = knn.predict(X_validate)\n",
    "    #print(classification_report(y_validate, y_validate))\n",
    "    print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4a249",
   "metadata": {},
   "source": [
    "### Regression Model Exercises\n",
    "\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5a946ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5dbe9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id', 'sex','sibsp','parch','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "31b4351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age     fare\n",
       "0         0       3  22.0   7.2500\n",
       "1         1       1  38.0  71.2833\n",
       "2         1       3  26.0   7.9250\n",
       "3         1       1  35.0  53.1000\n",
       "4         0       3  35.0   8.0500"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "224f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "79da0739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "baseline_accuracy = (0 == train.survived).mean()\n",
    "\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3cdb833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d8d38676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d3628da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9a4fefad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8eddd4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.94961658 -0.03063394  0.00141006]]\n",
      "Intercept: \n",
      " [2.52863437]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b26752e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7cd0d6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "83df6a6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36987005, 0.63012995],\n",
       "       [0.63806591, 0.36193409],\n",
       "       [0.61743881, 0.38256119],\n",
       "       [0.70383651, 0.29616349],\n",
       "       [0.30458292, 0.69541708],\n",
       "       [0.56359759, 0.43640241],\n",
       "       [0.65720071, 0.34279929],\n",
       "       [0.55318395, 0.44681605],\n",
       "       [0.7719031 , 0.2280969 ],\n",
       "       [0.75619804, 0.24380196]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(X_train)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f1ba2025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "46dbf1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369870</td>\n",
       "      <td>0.630130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638066</td>\n",
       "      <td>0.361934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617439</td>\n",
       "      <td>0.382561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703837</td>\n",
       "      <td>0.296163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304583</td>\n",
       "      <td>0.695417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.369870  0.630130\n",
       "1  0.638066  0.361934\n",
       "2  0.617439  0.382561\n",
       "3  0.703837  0.296163\n",
       "4  0.304583  0.695417"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "301bd351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ff723832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  41]\n",
      " [107  84]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f0dfd74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       307\n",
      "           1       0.67      0.44      0.53       191\n",
      "\n",
      "    accuracy                           0.70       498\n",
      "   macro avg       0.69      0.65      0.66       498\n",
      "weighted avg       0.70      0.70      0.69       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e45ab",
   "metadata": {},
   "source": [
    "2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4c1eb5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b9913a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id','sibsp','parch','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns = cols_to_drop)\n",
    "dummy_titanic = pd.get_dummies(titanic.sex, dummy_na = False, drop_first = True)\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis = 1)\n",
    "titanic = titanic.drop(columns = 'sex')\n",
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5a9b8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "382c7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "dad74dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "54b69956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3cba3aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.21048734e+00 -2.97258240e-02 -2.02978353e-03 -2.71609100e+00]]\n",
      "Intercept: \n",
      " [4.84166149]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "20439a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ce1776ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.558849</td>\n",
       "      <td>0.441151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859975</td>\n",
       "      <td>0.140025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857482</td>\n",
       "      <td>0.142518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.292842</td>\n",
       "      <td>0.707158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074243</td>\n",
       "      <td>0.925757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.558849  0.441151\n",
       "1  0.859975  0.140025\n",
       "2  0.857482  0.142518\n",
       "3  0.292842  0.707158\n",
       "4  0.074243  0.925757"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1d3a2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6640c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  41]\n",
      " [ 52 139]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c324b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       307\n",
      "           1       0.77      0.73      0.75       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.80      0.80       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1632e2",
   "metadata": {},
   "source": [
    "3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4c938c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "72c63156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out model w class, age, fare, encoded sex and parch\n",
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id','sibsp','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns = cols_to_drop)\n",
    "dummy_titanic = pd.get_dummies(titanic.sex, dummy_na = False, drop_first = True)\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis = 1)\n",
    "titanic = titanic.drop(columns = 'sex')\n",
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8e068003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0a6e3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "8e3bd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "abb6d1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "699b0ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.18892617e+00 -3.13159914e-02 -1.77144249e-01 -1.16024145e-03\n",
      "  -2.77684763e+00]]\n",
      "Intercept: \n",
      " [4.92074498]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9db39c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "928ee079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554522</td>\n",
       "      <td>0.445478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889223</td>\n",
       "      <td>0.110777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.865912</td>\n",
       "      <td>0.134088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316526</td>\n",
       "      <td>0.683474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.935421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.554522  0.445478\n",
       "1  0.889223  0.110777\n",
       "2  0.865912  0.134088\n",
       "3  0.316526  0.683474\n",
       "4  0.064579  0.935421"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6df32be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2ec4e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268  39]\n",
      " [ 53 138]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "50c01ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       307\n",
      "           1       0.78      0.72      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.81      0.80      0.80       498\n",
      "weighted avg       0.81      0.82      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d93a6b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "cda06a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out model w class, age, fare, encoded sex and sibsp\n",
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id','parch','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns = cols_to_drop)\n",
    "dummy_titanic = pd.get_dummies(titanic.sex, dummy_na = False, drop_first = True)\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis = 1)\n",
    "titanic = titanic.drop(columns = 'sex')\n",
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "92354f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "eda132d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "cc4368a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b3f776f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1579419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a912cd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.546985</td>\n",
       "      <td>0.453015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820058</td>\n",
       "      <td>0.179942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951423</td>\n",
       "      <td>0.048577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272681</td>\n",
       "      <td>0.727319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054659</td>\n",
       "      <td>0.945341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.546985  0.453015\n",
       "1  0.820058  0.179942\n",
       "2  0.951423  0.048577\n",
       "3  0.272681  0.727319\n",
       "4  0.054659  0.945341"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b0081802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "fc8b7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  48]\n",
      " [ 53 138]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b0035d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       307\n",
      "           1       0.74      0.72      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d8dbe8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "adc10a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out model w class, age, fare, encoded sex, sibsp and parch\n",
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns = cols_to_drop)\n",
    "dummy_titanic = pd.get_dummies(titanic.sex, dummy_na = False, drop_first = True)\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis = 1)\n",
    "titanic = titanic.drop(columns = 'sex')\n",
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b8750307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f117ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "4a0b37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d016f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6f057033",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6551bc7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.546144</td>\n",
       "      <td>0.453856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.831749</td>\n",
       "      <td>0.168251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950818</td>\n",
       "      <td>0.049182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278926</td>\n",
       "      <td>0.721074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053076</td>\n",
       "      <td>0.946924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.546144  0.453856\n",
       "1  0.831749  0.168251\n",
       "2  0.950818  0.049182\n",
       "3  0.278926  0.721074\n",
       "4  0.053076  0.946924"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ce829723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "fab17ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  48]\n",
      " [ 53 138]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "52964a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       307\n",
      "           1       0.74      0.72      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "b626f5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ded6a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out model w class, age, fare, encoded sex, sibsp and is_minor\n",
    "titanic = titanic.drop_duplicates()\n",
    "cols_to_drop = ['passenger_id', 'parch','embarked','class','deck','embark_town','alone']\n",
    "titanic = titanic.drop(columns = cols_to_drop)\n",
    "dummy_titanic = pd.get_dummies(titanic.sex, dummy_na = False, drop_first = True)\n",
    "titanic = pd.concat([titanic, dummy_titanic], axis = 1)\n",
    "titanic = titanic.drop(columns = 'sex')\n",
    "titanic['is_minor'] = (titanic['age']  < 13).astype(int)\n",
    "# plugging missing age values with mean of entire dataset\n",
    "titanic.age = titanic.age.fillna(value = titanic.age.mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "244d0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titanic\n",
    "train, test = train_test_split(titanic, test_size = .2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4f2ae469",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2be94c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "893def57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e0d61699",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7ebefa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.549621</td>\n",
       "      <td>0.450379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749710</td>\n",
       "      <td>0.250290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932588</td>\n",
       "      <td>0.067412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238133</td>\n",
       "      <td>0.761867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.942309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.549621  0.450379\n",
       "1  0.749710  0.250290\n",
       "2  0.932588  0.067412\n",
       "3  0.238133  0.761867\n",
       "4  0.057691  0.942309"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = [0, 1])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "7c34ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a1823895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269  38]\n",
      " [ 56 135]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c5d75ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       307\n",
      "           1       0.78      0.71      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.80       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c34939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ae4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3ab90a4",
   "metadata": {},
   "source": [
    "4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d8a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52def6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80856272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d040710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790cb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5793175",
   "metadata": {},
   "source": [
    "5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978a526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
